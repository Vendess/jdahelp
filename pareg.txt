***
url = "https://raw.githubusercontent.com/Vendess/jdahelp/refs/heads/main/papapa.txt"
response = requests.get(url)
print(response.text)
***


import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt 

=================================
=================================

1 Definovanie premenn√Ωch X a y
V≈ædy si mus√≠me na zaƒçiatku po naƒç√≠tan√∫ datasetu definova≈• predikuj√∫ce atrib√∫ty a cieƒæov√Ω atrib√∫t:

X ‚Äì predstavuje predikuj√∫ci atrib√∫t/atrib√∫ty
y ‚Äì predstavuje cieƒæov√Ω (predikovan√Ω) atrib√∫t
V na≈°om pr√≠pade (line√°rna regresia):
V na≈°ej √∫lohe predikujeme plat (Salary) na z√°klade rokov sk√∫senost√≠ (YearsExperience).

X = data[["YearsExperience"]]
y = data["Salary"]
Keby si chcel pri in√Ωch modeloch ako napr√≠klad Random Forest predikova≈• cieƒæov√Ω atrib√∫t pomocou v≈°etk√Ωch ostatn√Ωch atrib√∫tov, postup a z√°kladn√Ω princ√≠p ost√°va rovnak√Ω a pou≈æ√≠va sa z√°pis, ktor√Ωm do premennej X ulo≈æ√≠me v≈°etky atrib√∫ty okrem cieƒæov√©ho. V k√≥de to potom m√¥≈æe vyzera≈• nasledovne:

X = data.drop("Cieƒæov√Ω atrib√∫t", axis=1)
y = data["Cieƒæov√Ω atrib√∫t"]

=================================
=================================

salary = pd.read_csv("Salary_Data.csv")

X = salary[["YearsExperience"]]
y = salary["Salary"]

=================================
=================================

2 Rozdelenie d√°t na tr√©novaciu a testovaciu mno≈æinu
Druh√Ωm krokom je rozdeli≈• mno≈æinu d√°t na tr√©novaciu a testovaciu ƒças≈•, aby sme mohli model natr√©nova≈• na tr√©novac√≠ch d√°tach a n√°sledne overi≈•, ako dobre sa n√°≈° model uƒç√≠ na nov√Ωch d√°tach.

Praktick√° implement√°cia:
Pou≈æijeme 70 % d√°t na tr√©novanie a 30 % na testovanie. M√¥≈æete v≈°ak zvoli≈• aj in√© pomery, napr√≠klad 80:20.
Na rozdelenie pou≈æ√≠vame pr√≠kaz train_test_split z kni≈ænice scikit-learn.

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)
Pozn√°mky:
test_size=0.3 ‚Üí 30 % d√°t p√¥jde do testovacej mno≈æiny
random_state=1 ‚Üí zabezpeƒç√≠, ≈æe rozdelenie d√°t bude v≈ædy rovnak√© (reprodukovateƒæn√©)
Po rozdelen√≠ m√¥≈æeme overi≈• rozmery d√°t:
X_train.shape, X_test.shape
Z√°kladn√Ω princ√≠p ost√°va rovnak√Ω pre v≈°etky modely:

X_train, y_train ‚Üí d√°ta, na ktor√Ωch sa model uƒç√≠
X_test, y_test ‚Üí d√°ta, na ktor√Ωch sa model testuje

=================================
=================================

# Praktick√° implement√°cia
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)

X_train.shape, X_test.shape

=================================
=================================

3 Vytvorenie a natr√©novanie modelu
Tret√≠m krokom je vytvorenie modelu.
Ka≈æd√Ω model m√° svoj VLASTN√ù pr√≠kaz na inicializ√°ciu.
V na≈°om pr√≠pade pou≈æijeme model Line√°rnej regresie z kni≈ænice sklearn.linear_model.

Praktick√° implement√°cia:
Vytvor√≠me objekt modelu a n√°sledne ho natr√©nujeme (fitujeme) na tr√©novac√≠ch d√°tach X_train a y_train.

from sklearn.linear_model import LinearRegression

# vytvorenie modelu
model = LinearRegression()

# tr√©novanie (fitovanie) modelu na tr√©novac√≠ch d√°tach
model.fit(X_train, y_train)
Pozn√°mka:
Fitovanie = tr√©novanie modelu ‚Üí model sa uƒç√≠ vz≈•ah medzi predikuj√∫cim/predikuj√∫cimi atrib√∫tmi a cieƒæov√Ωm atrib√∫tom
V≈ædy pou≈æ√≠vame na tr√©novanie modelu tr√©novacie d√°ta (X_train, y_train), nikdy testovacie

=================================
=================================

#Praktick√° implement√°cia
from sklearn.linear_model import LinearRegression

model=LinearRegression()
model.fit(X_train,y_train)

=================================
=================================

4 Predikcia hodn√¥t pomocou vytvoren√©ho modelu
Po natr√©novan√≠ m√¥≈æeme model pou≈æi≈• na predikciu hodn√¥t pre nov√© d√°ta, napr√≠klad testovaciu mno≈æinu.

Praktick√° implement√°cia:
üí¨ Pou≈æijeme tr√©novan√Ω model na predikciu hodn√¥t pre testovaciu mno≈æinu X_test.

# predikcia hodn√¥t
y_pred = model.predict(X_test)
Pozn√°mka:
Predikciu vykon√°vame v≈ædy na d√°tach, ktor√© model e≈°te nevidel (testovacia mno≈æina)
Hodnoty y_pred m√¥≈æeme n√°sledne pou≈æi≈• na vyhodnotenie presnosti modelu, napr√≠klad pomocou metrik R¬≤, MAE alebo MSE

=================================
=================================

y_pred = model.predict(X_test)

=================================
=================================

5 Vizualiz√°cia a vyhodnotenie modelu
Po predikcii hodn√¥t m√¥≈æeme vizualizova≈• porovnanie skutoƒçn√Ωch a predikovan√Ωch hodn√¥t pomocou scatterplotu a z√°rove≈à model vyhodnoti≈• pomocou metr√≠k ako R¬≤ ƒçi MAPE.

Praktick√° implement√°cia ‚Äì scatterplot:
~~~ Porovnanie predikovan√Ωch hodn√¥t s testovac√≠mi d√°tami.

import matplotlib.pyplot as plt

plt.scatter(X_test, y_test, color='green', label='Testing Data')
plt.plot(X_test, y_pred, color='orange', label='Prediction Line')
plt.title('Testing Data')
plt.xlabel('YearsExperience')
plt.ylabel('Salary')
plt.legend()
plt.show()
Praktick√° implement√°cia ‚Äì vyhodnotenie pomocou metr√≠k:

~~~ Pou≈æijeme metriky R¬≤ a MAPE. Pre in√© typy √∫loh m√¥≈æeme vyu≈æi≈• aj MSE alebo MAE pr√≠padne v≈°etky. Uvedomte si, ≈æe v√Ωber vhodn√Ωch metr√≠k na testovanie z√°vis√≠ od viacer√Ωch vec√≠ ako napr√≠klad modelu, typu √∫lohy, samotn√©ho cieƒæa.

from sklearn.metrics import r2_score, mean_absolute_percentage_error

r2 = r2_score(y_test, y_pred)
mape = mean_absolute_percentage_error(y_test, y_pred)

print(f"R¬≤: {r2:.4f}")
print(f"MAPE: {mape:.4f}")

=================================
=================================

import matplotlib.pyplot as plt

plt.scatter(X_test, y_test, color='green', label='Testing Data')
plt.plot(X_test, y_pred, color='orange', label='Prediction Line')
plt.title('Testing Data')
plt.xlabel('YearsExperience')
plt.ylabel('Salary')
plt.legend()
plt.show()

===
===

from sklearn.metrics import r2_score, mean_absolute_percentage_error

r2 = r2_score(y_test, y_pred)
mape = mean_absolute_percentage_error(y_test, y_pred)

print(f"R¬≤: {r2:.4f}")
print(f"MAPE: {mape:.4f}")

=================================
=================================
